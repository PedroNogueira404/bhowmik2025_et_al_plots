{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc46af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_PROJECT = os.path.dirname(os.getcwd())\n",
    "SOURCE_PROJECT = os.path.join(ROOT_PROJECT,\"src/bhowmik2025_et_al_plots\")\n",
    "input_dir = os.path.join(SOURCE_PROJECT, \"input_files\")\n",
    "FITS_DIR = os.path.join(input_dir, \"fits_files\")\n",
    "RADIAL_PROF_DIR = os.path.join(input_dir, \"frank_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "636b5246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mismatch - It is safe to merge!! \n",
      " ##################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202 entries, 0 to 201\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        202 non-null    int64 \n",
      " 1   field     202 non-null    object\n",
      " 2   is model  202 non-null    bool  \n",
      " 3   path      202 non-null    object\n",
      " 4   path_rad  202 non-null    object\n",
      "dtypes: bool(1), int64(1), object(3)\n",
      "memory usage: 6.6+ KB\n",
      "################################################## \n",
      " Saved table.csv successfully! None \n",
      " ##################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    101 non-null    int64  \n",
      " 1   field                 101 non-null    object \n",
      " 2   path                  101 non-null    object \n",
      " 3   path_rad              101 non-null    object \n",
      " 4   path_model            101 non-null    object \n",
      " 5   beam_pa               101 non-null    float64\n",
      " 6   beam_maj              101 non-null    float64\n",
      " 7   beam_min              101 non-null    float64\n",
      " 8   center_x              101 non-null    object \n",
      " 9   center_y              101 non-null    object \n",
      " 10  Distance              101 non-null    float64\n",
      " 11  Rmax_frank            101 non-null    float64\n",
      " 12  B8_Flux               101 non-null    float64\n",
      " 13  isbinary              101 non-null    int64  \n",
      " 14  rms_data              101 non-null    float64\n",
      " 15  rms_model_profile     101 non-null    float64\n",
      " 16  Class                 101 non-null    object \n",
      " 17  Features              101 non-null    object \n",
      " 18  R_zoom                101 non-null    float64\n",
      " 19  rms_model_percentage  101 non-null    float64\n",
      " 20  Stage                 101 non-null    int64  \n",
      " 21  Group                 101 non-null    object \n",
      "dtypes: float64(10), int64(3), object(9)\n",
      "memory usage: 17.5+ KB\n",
      "################################################## \n",
      " Saved full_table.csv successfully! None \n",
      " ##################################################\n"
     ]
    }
   ],
   "source": [
    "# Check if the directory exists\n",
    "if not os.path.exists(FITS_DIR):\n",
    "    raise Exception(f\"Directory {FITS_DIR} does not exist.\")\n",
    "\n",
    "# Create a pandas dataframe of all .fits files in the directory, \n",
    "# with their full paths  \n",
    "\n",
    "rows : list = []\n",
    "counter=0\n",
    "for file in os.listdir(FITS_DIR):\n",
    "    if file.endswith(\".fits\"):\n",
    "        has_odisea : str = \"ODISEA\" in file\n",
    "        # has_odisea = 0 if has_odisea else False\n",
    "        \n",
    "        has_frank : str = \"frank\" in file\n",
    "        ismodel : bool = True if has_frank else False\n",
    "        \n",
    "        has_iso_oph : str = \"ISO_Oph\" in file\n",
    "        # is_iso_oph = True if has_iso_oph else False\n",
    "        \n",
    "        has_ra : str = \"RA\" in file\n",
    "        # is_ra = True if has_ra else False \n",
    "        \n",
    "        ### YOU NEED TO CHECK IF THE NEXT CONDITIONS ARE CORRECT BY \n",
    "        ### COMPARING THE TABLES (NUMBER OF ROWS)####\n",
    "        if has_odisea:\n",
    "            source_list : list = re.split(r\"[_]+\", file)[0:3]\n",
    "        elif has_ra:\n",
    "            source_list : list = re.split(r\"[_]+\", file)[0:1]\n",
    "        else:\n",
    "            source_list : list = re.split(r\"[_]+\", file)[0:2]\n",
    "        #############################################################\n",
    "        \n",
    "        source = \"_\".join(source_list)\n",
    "        path = os.path.join(FITS_DIR, file)\n",
    "        rows.append({\"id\":counter,\"field\": source, \"is model\": ismodel, \"path\": path})\n",
    "        counter+=1\n",
    "\n",
    "rows_rad = []\n",
    "\n",
    "for file_rad in os.listdir(RADIAL_PROF_DIR):\n",
    "    if file_rad.endswith(\".txt\"):\n",
    "        has_odisea : str = \"ODISEA\" in file_rad\n",
    "        has_iso_oph : str = \"ISO_Oph\" in file_rad\n",
    "        has_ra : str = \"RA\" in file_rad\n",
    "        \n",
    "        ### YOU NEED TO CHECK IF THE NEXT CONDITIONS ARE CORRECT BY \n",
    "        ### COMPARING THE TABLES (NUMBER OF ROWS)####\n",
    "        if has_odisea:\n",
    "            source_list : list = re.split(r\"[_]+\", file_rad)[0:3]\n",
    "        elif has_ra:\n",
    "            source_list : list = re.split(r\"[_]+\", file_rad)[0:1]\n",
    "        else:\n",
    "            source_list : list = re.split(r\"[_]+\", file_rad)[0:2]\n",
    "        #############################################################\n",
    "        \n",
    "        source = \"_\".join(source_list)\n",
    "        path = os.path.join(RADIAL_PROF_DIR, file_rad)\n",
    "        rows_rad.append({\"field_rad\": source, \"path_rad\": path})\n",
    "\n",
    "\n",
    "######### Create a pandas dataframe with the rows ###################\n",
    "##### rows = [{\"id\":dummy-counter ,\"field\": source, \"is model\": bolean,\n",
    "# \"path\": path-to-fits-files, \"path_rad\": path-to-png-radial-profs}]         \n",
    "table = pd.DataFrame(rows, columns=[\"id\",\"field\", \"is model\",\"path\"])\n",
    "table = pd.merge(table, pd.DataFrame(rows_rad),\n",
    "                 left_on=\"field\", right_on=\"field_rad\").drop(\"field_rad\", axis=1)\n",
    "\n",
    "# Sorting, fixing indexes, fixing \"field\" problems\n",
    "table = table.sort_values(by=[\"field\"])\n",
    "table = table.reset_index(drop=True)\n",
    "table['id'] = table.index\n",
    "table[\"field\"] = table[\"field\"].str.strip().str.lower()\n",
    "##########################################################\n",
    "# Creating a data and model identical tables to merge them again\n",
    "# keeping path of data and model in the same lines of full_table\n",
    "table_realdata_nomodelcol = table[table[\"is model\"]==False].drop(\"is model\",axis=1).reset_index(drop=True)\n",
    "table_realdata_nomodelcol['id'] = table_realdata_nomodelcol.index\n",
    "table_model_nomodelcol = table[table[\"is model\"]==True].drop(\"is model\",axis=1).reset_index(drop=True)\n",
    "table_model_nomodelcol['id'] = table_model_nomodelcol.index\n",
    "table_model_nomodelcol = table_model_nomodelcol.rename(columns={'path':'path_model'})\n",
    "#### IMPORTANT: table_nomodelcol is the full table predecessor,\n",
    "# before merging with the table Trisha gave me\n",
    "# Dont make confusion!!\n",
    "table_nomodelcol =  pd.merge(table_realdata_nomodelcol,\n",
    "                          table_model_nomodelcol,\n",
    "                          left_on=(\"field\",\"id\",\"path_rad\"),\n",
    "                          right_on=(\"field\",\"id\",\"path_rad\"),\n",
    "                          validate='1:1')\n",
    "#####################################################################\n",
    "\n",
    "######### Read table that Trisha gave me ###########\n",
    "table_sizes = pd.read_csv(f\"{input_dir}/table.csv\", index_col=False)\n",
    "\n",
    "# Standardize the 'field' column in table_sizes by stripping whitespace and \n",
    "# converting to lowercase\n",
    "table_sizes[\"field\"] = table_sizes[\"field\"].str.strip().str.lower()\n",
    "table_sizes = table_sizes.sort_values(by=[\"field\"])\n",
    "#####################################################################\n",
    "\n",
    "########## Debugging mismatches! #####################\n",
    "# Find rows in table_realdata_nomodelcol that do not have a match \n",
    "# in table_sizes\n",
    "not_in_sizes = table_nomodelcol.merge(\n",
    "    table_sizes,\n",
    "    on=[\"id\", \"field\"],\n",
    "    how=\"left\",\n",
    "    indicator=True).query('_merge == \"left_only\"')\n",
    "\n",
    "# Find rows in table_sizes that do not have a match in \n",
    "# table_realdata_nomodelcol\n",
    "not_in_realdata = table_sizes.merge(\n",
    "    table_nomodelcol,\n",
    "    on=[\"id\", \"field\"],\n",
    "    how=\"left\",\n",
    "    indicator=True).query('_merge == \"left_only\"')\n",
    "\n",
    "# print(\"Rows in table_realdata_nomodelcol not in table_sizes:\")\n",
    "# print(not_in_sizes)\n",
    "\n",
    "# print(\"\\nRows in table_sizes not in table_realdata_nomodelcol:\")\n",
    "# print(not_in_realdata)\n",
    "\n",
    "########## Merge the two tables ##############################\n",
    "if not_in_sizes.empty and not_in_realdata.empty:\n",
    "    print(\"There is no mismatch - It is safe to merge!!\",\"\\n\", 50*\"#\")\n",
    "    full_table = pd.merge(table_nomodelcol,\n",
    "                          table_sizes,\n",
    "                          left_on=(\"field\",\"id\"),\n",
    "                          right_on=(\"field\",\"id\"),\n",
    "                          validate='1:1')\n",
    "    \n",
    "#####################################################################\n",
    "\n",
    "####Now fix the center_x and center_y for using of astropy before exporting\n",
    "# full table:\n",
    "def fix_center_x(s):\n",
    "    # If there are 3 colons, replace the last colon with a dot\n",
    "    if s.count(':') == 3:\n",
    "        s = s[::-1].replace(':', '.', 1)[::-1]\n",
    "    return s\n",
    "\n",
    "def fix_center_y(s):\n",
    "    # Replace the first two dots with colons\n",
    "    return s.replace('.', ':', 2)\n",
    "\n",
    "# Apply to my DataFrame\n",
    "full_table['center_x'] = full_table['center_x'].astype(str).apply(fix_center_x)\n",
    "full_table['center_y'] = full_table['center_y'].astype(str).apply(fix_center_y)\n",
    "\n",
    "# df['Class'] = df['Class'].replace({'I': 'I/F', 'F': 'I/F'})\n",
    "# df['Group'] = df['Features'] + '+' + df['Class']\n",
    "# grouped = df.groupby('Group')\n",
    "\n",
    "full_table['Class'] = full_table['Class'].replace({'I': 'I_F', 'F': 'I_F'})\n",
    "full_table[\"Group\"] = full_table[\"Stage\"].astype(str) + \"+\" + full_table[\"Class\"]\n",
    "full_table[\"Group\"] = full_table[\"Group\"].str.strip()\n",
    "# grouped = full_table.groupby('Group')\n",
    "\n",
    "# full_table_expanded = full_table.assign(Group=full_table['Features'].str.split(',')).explode('Group')\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'] + '+' + full_table_expanded['Class']#.replace({'I': 'I_F', 'F': 'I_F'})\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'].str.strip()\n",
    "\n",
    "try:\n",
    "    table.to_csv(f\"{os.getcwd()}/fits_files.csv\", index=False)\n",
    "    print(50*\"#\", \"\\n\",\"Saved table.csv successfully!\",\n",
    "          table.info(verbose=True),\n",
    "          \"\\n\", 50*\"#\")\n",
    "    full_table.to_csv(f\"{os.getcwd()}/full_table.csv\", index=False)\n",
    "    print(50*\"#\", \"\\n\",\"Saved full_table.csv successfully!\",\n",
    "          full_table.info(verbose=True), \"\\n\", 50*\"#\")\n",
    "    \n",
    "    # full_table_expanded = full_table.explode('Group')\n",
    "    # full_table_expanded.to_csv(f\"{os.getcwd()}/full_table_expanded.csv\", index=False)\n",
    "    # print(50*\"#\", \"\\n\",\"Saved full_table_expanded.csv successfully!\",\n",
    "    #       full_table_expanded.info(verbose=True), \"\\n\", 50*\"#\")\n",
    "    \n",
    "    # print(table.info(), full_table.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "# full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
