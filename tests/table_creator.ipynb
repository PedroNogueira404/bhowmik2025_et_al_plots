{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dc46af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_PROJECT = os.path.dirname(os.getcwd())\n",
    "SOURCE_PROJECT = os.path.join(ROOT_PROJECT,\"src/bhowmik2025_et_al_plots\")\n",
    "input_dir = os.path.join(SOURCE_PROJECT, \"input_files\")\n",
    "FITS_DIR = os.path.join(input_dir, \"fits_files\")\n",
    "DATA_RES_DIR = os.path.join(FITS_DIR, \"spec_avg_data_residual\")\n",
    "RADIAL_PROF_DIR = os.path.join(input_dir, \"frank_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['field', 'path_data', 'path_rad', 'path_avg_data'], dtype='object') Index(['field', 'path_model', 'path_rad', 'path_residual'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "field",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path_data",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path_rad",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path_avg_data",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path_model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path_residual",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "aa18b9a9-e15b-4e9f-acbf-5bd468ba0aa6",
       "rows": [
        [
         "0",
         "iso-oph_123",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_123_all_p0_bigmask.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/frank_profiles/ISO-Oph_123_frank_profile_fit.txt",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_123_data.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_123_frank_model.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_123_residual.fits"
        ],
        [
         "1",
         "iso-oph_13",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_13_all_p0_bigmask.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/frank_profiles/ISO-Oph_13_frank_profile_fit.txt",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_13_data.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_13_frank_model.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_13_residual.fits"
        ],
        [
         "2",
         "iso-oph_193",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_193_all_p0_bigmask.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/frank_profiles/ISO-Oph_193_frank_profile_fit.txt",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_193_data.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_193_frank_model.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_193_residual.fits"
        ],
        [
         "3",
         "iso-oph_208",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_208_all_p0_bigmask.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/frank_profiles/ISO-Oph_208_frank_profile_fit.txt",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_208_data.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/ISO-Oph_208_frank_model.fits",
         "/home/pnogueira/chewiepoint/bhowmik_2025/bhowmik2025_et_al_plots/src/bhowmik2025_et_al_plots/input_files/fits_files/spec_avg_data_residual/ISO-Oph_208_residual.fits"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>path_data</th>\n",
       "      <th>path_rad</th>\n",
       "      <th>path_avg_data</th>\n",
       "      <th>path_model</th>\n",
       "      <th>path_residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iso-oph_123</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iso-oph_13</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iso-oph_193</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iso-oph_208</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "      <td>/home/pnogueira/chewiepoint/bhowmik_2025/bhowm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         field                                          path_data  \\\n",
       "0  iso-oph_123  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "1   iso-oph_13  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "2  iso-oph_193  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "3  iso-oph_208  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "\n",
       "                                            path_rad  \\\n",
       "0  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "1  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "2  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "3  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "\n",
       "                                       path_avg_data  \\\n",
       "0  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "1  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "2  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "3  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "\n",
       "                                          path_model  \\\n",
       "0  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "1  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "2  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "3  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...   \n",
       "\n",
       "                                       path_residual  \n",
       "0  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...  \n",
       "1  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...  \n",
       "2  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...  \n",
       "3  /home/pnogueira/chewiepoint/bhowmik_2025/bhowm...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the directory exists\n",
    "if not os.path.exists(FITS_DIR):\n",
    "    raise Exception(f\"Directory {FITS_DIR} does not exist.\")\n",
    "\n",
    "# Create a pandas dataframe of all .fits files in the directory,\n",
    "# with their full paths\n",
    "\n",
    "rows: list = []\n",
    "counter = 0\n",
    "for file in os.listdir(FITS_DIR):\n",
    "    if file.endswith(\".fits\"):\n",
    "        has_odisea: str = \"ODISEA\" in file\n",
    "        # has_odisea = 0 if has_odisea else False\n",
    "\n",
    "        has_frank: str = \"frank\" in file\n",
    "        ismodel: bool = True if has_frank else False\n",
    "\n",
    "        has_iso_oph: str = \"ISO_Oph\" in file\n",
    "        # is_iso_oph = True if has_iso_oph else False\n",
    "\n",
    "        has_ra: str = \"RA\" in file\n",
    "        # is_ra = True if has_ra else False\n",
    "\n",
    "        ### YOU NEED TO CHECK IF THE NEXT CONDITIONS ARE CORRECT BY\n",
    "        ### COMPARING THE TABLES (NUMBER OF ROWS)####\n",
    "        if has_odisea:\n",
    "            source_list: list = re.split(r\"[_]+\", file)[0:3]\n",
    "        elif has_ra:\n",
    "            source_list: list = re.split(r\"[_]+\", file)[0:1]\n",
    "        else:\n",
    "            source_list: list = re.split(r\"[_]+\", file)[0:2]\n",
    "        #############################################################\n",
    "\n",
    "        source = \"_\".join(source_list)\n",
    "        path = os.path.join(FITS_DIR, file)\n",
    "        rows.append({\"id\": counter, \"field\": source, \"is model\": ismodel, \"path\": path})\n",
    "        counter += 1\n",
    "\n",
    "rows_rad = []\n",
    "\n",
    "for file_rad in os.listdir(RADIAL_PROF_DIR):\n",
    "    if file_rad.endswith(\".txt\"):\n",
    "        has_odisea: str = \"ODISEA\" in file_rad\n",
    "        has_iso_oph: str = \"ISO_Oph\" in file_rad\n",
    "        has_ra: str = \"RA\" in file_rad\n",
    "\n",
    "        ### YOU NEED TO CHECK IF THE NEXT CONDITIONS ARE CORRECT BY\n",
    "        ### COMPARING THE TABLES (NUMBER OF ROWS)####\n",
    "        if has_odisea:\n",
    "            source_list: list = re.split(r\"[_]+\", file_rad)[0:3]\n",
    "        elif has_ra:\n",
    "            source_list: list = re.split(r\"[_]+\", file_rad)[0:1]\n",
    "        else:\n",
    "            source_list: list = re.split(r\"[_]+\", file_rad)[0:2]\n",
    "        #############################################################\n",
    "\n",
    "        source = \"_\".join(source_list)\n",
    "        path = os.path.join(RADIAL_PROF_DIR, file_rad)\n",
    "        rows_rad.append({\"field_rad\": source, \"path_rad\": path})\n",
    "\n",
    "rows_data_res: list = []\n",
    "# for counter, file in enumerate(os.listdir(paths.data_res_dir)):\n",
    "for file_data_res in os.listdir(DATA_RES_DIR):\n",
    "    if file_data_res.endswith(\".fits\"):\n",
    "        # has_spec_avg_data: str = \"data\" in file\n",
    "\n",
    "        has_resid: str = \"residual\" in file_data_res\n",
    "        isres: bool = True if has_resid else False\n",
    "\n",
    "        has_odisea: str = \"ODISEA\" in file_data_res\n",
    "        has_ra: str = \"RA\" in file_data_res\n",
    "\n",
    "        ### YOU NEED TO CHECK IF THE NEXT CONDITIONS ARE CORRECT BY\n",
    "        ### COMPARING THE TABLES (NUMBER OF ROWS)####\n",
    "        if has_odisea:\n",
    "            source_list: list = re.split(r\"[_]+\", file_data_res)[0:3]\n",
    "        elif has_ra:\n",
    "            source_list: list = re.split(r\"[_]+\", file_data_res)[0:1]\n",
    "        else:\n",
    "            source_list: list = re.split(r\"[_]+\", file_data_res)[0:2]\n",
    "        #############################################################\n",
    "\n",
    "        source = \"_\".join(source_list)\n",
    "        # path = os.path.join(paths.fits_dir, file)\n",
    "        rows_data_res.append(\n",
    "            {\n",
    "                # \"id\": counter,\n",
    "                \"field_res\": source,\n",
    "                \"is res\": isres,\n",
    "                \"path_data_res\": os.path.join(DATA_RES_DIR, file_data_res),\n",
    "            }\n",
    "        )\n",
    "\n",
    "######### Create a pandas dataframe with the rows ###################\n",
    "##### rows = [{\"id\":dummy-counter ,\"field\": source, \"is model\": bolean,\n",
    "# \"path\": path-to-fits-files, \"path_rad\": path-to-png-radial-profs}]\n",
    "table = pd.DataFrame(rows, columns=[\"id\", \"field\", \"is model\", \"path\"])\n",
    "table = pd.merge(\n",
    "    table, pd.DataFrame(rows_rad), left_on=\"field\", right_on=\"field_rad\"\n",
    ").drop(\"field_rad\", axis=1)\n",
    "# print(table.head(), \"\\n\")\n",
    "table = pd.merge(\n",
    "    table,\n",
    "    pd.DataFrame(rows_data_res),\n",
    "    left_on=[\"field\", \"is model\"],\n",
    "    right_on=[\"field_res\", \"is res\"],\n",
    ").drop(\"field_res\", axis=1)\n",
    "# print(table.head())\n",
    "\n",
    "# Sorting, fixing indexes, fixing \"field\" problems\n",
    "table = table.sort_values(by=[\"field\"])\n",
    "table = table.reset_index(drop=True)\n",
    "table[\"id\"] = table.index\n",
    "table[\"field\"] = table[\"field\"].str.strip().str.lower()\n",
    "##########################################################\n",
    "# Creating a data and model identical tables to merge them again\n",
    "# keeping path of data and model in the same lines of full_table\n",
    "# table_realdata = (\n",
    "#     table[table[\"is model\"] == False].drop(\"is model\", axis=1).reset_index(drop=True)\n",
    "# )\n",
    "table_realdata = (\n",
    "    table[(~table[\"is model\"]) & (~table[\"is res\"])]\n",
    "    .drop(columns=[\"is model\", \"is res\", \"id\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# table_realdata[\"id\"] = table_realdata.index\n",
    "\n",
    "table_realdata = table_realdata.rename(\n",
    "    columns={\"path\": \"path_data\", \"path_data_res\": \"path_avg_data\"}\n",
    ")\n",
    "# table_realdata.head(2)\n",
    "\n",
    "table_model = (\n",
    "    table[table[\"is model\"] & table[\"is res\"]]\n",
    "    .drop(columns=[\"is model\", \"is res\", \"id\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "# table_realdata[\"id\"] = table_realdata.index\n",
    "# table_model = (\n",
    "#     table[table[\"is model\"] == True].drop(\"is model\", axis=1).reset_index(drop=True))\n",
    "# print(table_realdata.columns, \"\\n\")\n",
    "\n",
    "# table_realdata[\"id\"] = table_realdata.index\n",
    "# table_model = (\n",
    "#     table[table[\"is model\"] == True].drop(\"is model\", axis=1).reset_index(drop=True))\n",
    "# print(table_realdata.columns, \"\\n\")\n",
    "\n",
    "# table_model = (\n",
    "#     table[table[\"is model\"] == True].drop(columns=[\"is model\", \"is res\"]).reset_index(drop=True)\n",
    "# )\n",
    "# table_model[\"id\"] = table_model.index\n",
    "\n",
    "table_model = table_model.rename(\n",
    "    columns={\"path\": \"path_model\", \"path_data_res\": \"path_residual\"}\n",
    ")\n",
    "\n",
    "print(table_realdata.columns, table_model.columns)\n",
    "# table_model = table[table[\"is model\"] & table[\"is res\"]]\n",
    "\n",
    "# table_model.head(2)\n",
    "# table[table[\"is model\"] & table[\"is res\"]].drop(columns=[\"is model\", \"is res\"]).reset_index(drop=True).tail(3)\n",
    "# table_model.rename(columns={\"path\": \"path_model\",\"path_data_res\": \"path_residual\"})\n",
    "# table_model[\"id\"] = table_model.index\n",
    "# table_model = table_model.rename(columns={\"path\": \"path_model\"})\n",
    "# print(table_model.columns, \"\\n\")\n",
    "\n",
    "\n",
    "#### IMPORTANT: table_nomodelcol is the full table predecessor,\n",
    "# before merging with the table Trisha gave me\n",
    "# Dont make confusion!!\n",
    "table_nomodelcol = pd.merge(\n",
    "    table_realdata,\n",
    "    table_model,\n",
    "    left_on=(\"field\", \"path_rad\"),\n",
    "    right_on=(\"field\", \"path_rad\"),\n",
    "    validate=\"1:1\",\n",
    ").reset_index(drop=True)\n",
    "table_nomodelcol.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3a2f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'field', 'is model', 'path', 'path_rad', 'is res',\n",
       "       'path_data_res'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4349c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mismatch - It is safe to merge!! \n",
      " ##################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['field', 'path_data', 'path_rad', 'path_avg_data', 'path_model',\n",
       "       'path_residual', 'id', 'beam_pa', 'beam_maj', 'beam_min', 'center_x',\n",
       "       'center_y', 'Distance', 'Rmax_frank', 'B8_Flux', 'isbinary', 'rms_data',\n",
       "       'rms_model_profile', 'Class', 'Features', 'R_zoom',\n",
       "       'rms_model_percentage', 'Stage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################\n",
    "\n",
    "######### Read table that Trisha gave me ###########\n",
    "table_sizes = pd.read_csv(f\"{input_dir}/table.csv\", index_col=False)\n",
    "\n",
    "# Standardize the 'field' column in table_sizes by stripping whitespace and\n",
    "# converting to lowercase\n",
    "table_sizes[\"field\"] = table_sizes[\"field\"].str.strip().str.lower()\n",
    "table_sizes = table_sizes.sort_values(by=[\"field\"])\n",
    "#####################################################################\n",
    "\n",
    "########## Debugging mismatches! #####################\n",
    "# Find rows in table_realdata that do not have a match\n",
    "# in table_sizes\n",
    "not_in_sizes = table_nomodelcol.merge(\n",
    "    table_sizes, on=[\"field\"], how=\"left\", indicator=True\n",
    ").query('_merge == \"left_only\"')\n",
    "\n",
    "# Find rows in table_sizes that do not have a match in\n",
    "# table_realdata\n",
    "not_in_realdata = table_sizes.merge(\n",
    "    table_nomodelcol, on=[\"field\"], how=\"left\", indicator=True\n",
    ").query('_merge == \"left_only\"')\n",
    "\n",
    "# print(\"Rows in table_realdata not in table_sizes:\")\n",
    "# print(not_in_sizes)\n",
    "\n",
    "# print(\"\\nRows in table_sizes not in table_realdata:\")\n",
    "# print(not_in_realdata)\n",
    "\n",
    "########## Merge the two tables ##############################\n",
    "if not_in_sizes.empty and not_in_realdata.empty:\n",
    "    print(\"There is no mismatch - It is safe to merge!!\", \"\\n\", 50 * \"#\")\n",
    "    full_table = pd.merge(\n",
    "        table_nomodelcol,\n",
    "        table_sizes,\n",
    "        left_on=(\"field\"),\n",
    "        right_on=(\"field\"),\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "full_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202 entries, 0 to 201\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             202 non-null    int64 \n",
      " 1   field          202 non-null    object\n",
      " 2   is model       202 non-null    bool  \n",
      " 3   path           202 non-null    object\n",
      " 4   path_rad       202 non-null    object\n",
      " 5   is res         202 non-null    bool  \n",
      " 6   path_data_res  202 non-null    object\n",
      "dtypes: bool(2), int64(1), object(4)\n",
      "memory usage: 8.4+ KB\n",
      "################################################## \n",
      " Saved table.csv successfully! None \n",
      " ##################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   field                 101 non-null    object \n",
      " 1   path_data             101 non-null    object \n",
      " 2   path_rad              101 non-null    object \n",
      " 3   path_avg_data         101 non-null    object \n",
      " 4   path_model            101 non-null    object \n",
      " 5   path_residual         101 non-null    object \n",
      " 6   id                    101 non-null    int64  \n",
      " 7   beam_pa               101 non-null    float64\n",
      " 8   beam_maj              101 non-null    float64\n",
      " 9   beam_min              101 non-null    float64\n",
      " 10  center_x              101 non-null    object \n",
      " 11  center_y              101 non-null    object \n",
      " 12  Distance              101 non-null    float64\n",
      " 13  Rmax_frank            101 non-null    float64\n",
      " 14  B8_Flux               101 non-null    float64\n",
      " 15  isbinary              101 non-null    int64  \n",
      " 16  rms_data              101 non-null    float64\n",
      " 17  rms_model_profile     101 non-null    float64\n",
      " 18  Class                 101 non-null    object \n",
      " 19  Features              101 non-null    object \n",
      " 20  R_zoom                101 non-null    float64\n",
      " 21  rms_model_percentage  101 non-null    float64\n",
      " 22  Stage                 101 non-null    int64  \n",
      " 23  Group                 101 non-null    object \n",
      "dtypes: float64(10), int64(3), object(11)\n",
      "memory usage: 19.1+ KB\n",
      "################################################## \n",
      " Saved full_table.csv successfully! None \n",
      " ##################################################\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "\n",
    "\n",
    "####Now fix the center_x and center_y for using of astropy before exporting\n",
    "# full table:\n",
    "def fix_center_x(s):\n",
    "    # If there are 3 colons, replace the last colon with a dot\n",
    "    if s.count(\":\") == 3:\n",
    "        s = s[::-1].replace(\":\", \".\", 1)[::-1]\n",
    "    return s\n",
    "\n",
    "\n",
    "def fix_center_y(s):\n",
    "    # Replace the first two dots with colons\n",
    "    return s.replace(\".\", \":\", 2)\n",
    "\n",
    "\n",
    "# Apply to my DataFrame\n",
    "full_table[\"center_x\"] = full_table[\"center_x\"].astype(str).apply(fix_center_x)\n",
    "full_table[\"center_y\"] = full_table[\"center_y\"].astype(str).apply(fix_center_y)\n",
    "\n",
    "# df['Class'] = df['Class'].replace({'I': 'I/F', 'F': 'I/F'})\n",
    "# df['Group'] = df['Features'] + '+' + df['Class']\n",
    "# grouped = df.groupby('Group')\n",
    "\n",
    "full_table[\"Class\"] = full_table[\"Class\"].replace({\"I\": \"I_F\", \"F\": \"I_F\"})\n",
    "full_table[\"Group\"] = full_table[\"Stage\"].astype(str) + \"+\" + full_table[\"Class\"]\n",
    "full_table[\"Group\"] = full_table[\"Group\"].str.strip()\n",
    "# grouped = full_table.groupby('Group')\n",
    "\n",
    "# full_table_expanded = full_table.assign(Group=full_table['Features'].str.split(',')).explode('Group')\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'] + '+' + full_table_expanded['Class']#.replace({'I': 'I_F', 'F': 'I_F'})\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'].str.strip()\n",
    "\n",
    "try:\n",
    "    table.to_csv(f\"{os.getcwd()}/fits_files.csv\", index=False)\n",
    "    print(\n",
    "        50 * \"#\",\n",
    "        \"\\n\",\n",
    "        \"Saved table.csv successfully!\",\n",
    "        table.info(verbose=True),\n",
    "        \"\\n\",\n",
    "        50 * \"#\",\n",
    "    )\n",
    "    full_table.to_csv(f\"{os.getcwd()}/full_table.csv\", index=False)\n",
    "    print(\n",
    "        50 * \"#\",\n",
    "        \"\\n\",\n",
    "        \"Saved full_table.csv successfully!\",\n",
    "        full_table.info(verbose=True),\n",
    "        \"\\n\",\n",
    "        50 * \"#\",\n",
    "    )\n",
    "\n",
    "    # full_table_expanded = full_table.explode('Group')\n",
    "    # full_table_expanded.to_csv(f\"{os.getcwd()}/full_table_expanded.csv\", index=False)\n",
    "    # print(50*\"#\", \"\\n\",\"Saved full_table_expanded.csv successfully!\",\n",
    "    #       full_table_expanded.info(verbose=True), \"\\n\", 50*\"#\")\n",
    "\n",
    "    # print(table.info(), full_table.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "# full_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bd711",
   "metadata": {},
   "source": [
    "##########################################################\n",
    "# Creating a data and model identical tables to merge them again\n",
    "# keeping path of data and model in the same lines of full_table\n",
    "table_realdata = (\n",
    "    table[table[\"is model\"] == False].drop(\"is model\", axis=1).reset_index(drop=True)\n",
    ")\n",
    "table_realdata[\"id\"] = table_realdata.index\n",
    "table_model = (\n",
    "    table[table[\"is model\"] == True].drop(\"is model\", axis=1).reset_index(drop=True)\n",
    ")\n",
    "table_model[\"id\"] = table_model.index\n",
    "table_model = table_model.rename(columns={\"path\": \"path_model\"})\n",
    "#### IMPORTANT: table_nomodelcol is the full table predecessor,\n",
    "# before merging with the table Trisha gave me\n",
    "# Dont make confusion!!\n",
    "table_nomodelcol = pd.merge(\n",
    "    table_realdata,\n",
    "    table_model,\n",
    "    left_on=(\"field\", \"id\", \"path_rad\"),\n",
    "    right_on=(\"field\", \"id\", \"path_rad\"),\n",
    "    validate=\"1:1\",\n",
    ")\n",
    "#####################################################################\n",
    "\n",
    "######### Read table that Trisha gave me ###########\n",
    "table_sizes = pd.read_csv(f\"{input_dir}/table.csv\", index_col=False)\n",
    "\n",
    "# Standardize the 'field' column in table_sizes by stripping whitespace and\n",
    "# converting to lowercase\n",
    "table_sizes[\"field\"] = table_sizes[\"field\"].str.strip().str.lower()\n",
    "table_sizes = table_sizes.sort_values(by=[\"field\"])\n",
    "#####################################################################\n",
    "\n",
    "########## Debugging mismatches! #####################\n",
    "# Find rows in table_realdata that do not have a match\n",
    "# in table_sizes\n",
    "not_in_sizes = table_nomodelcol.merge(\n",
    "    table_sizes, on=[\"id\", \"field\"], how=\"left\", indicator=True\n",
    ").query('_merge == \"left_only\"')\n",
    "\n",
    "# Find rows in table_sizes that do not have a match in\n",
    "# table_realdata\n",
    "not_in_realdata = table_sizes.merge(\n",
    "    table_nomodelcol, on=[\"id\", \"field\"], how=\"left\", indicator=True\n",
    ").query('_merge == \"left_only\"')\n",
    "\n",
    "# print(\"Rows in table_realdata not in table_sizes:\")\n",
    "# print(not_in_sizes)\n",
    "\n",
    "# print(\"\\nRows in table_sizes not in table_realdata:\")\n",
    "# print(not_in_realdata)\n",
    "\n",
    "########## Merge the two tables ##############################\n",
    "if not_in_sizes.empty and not_in_realdata.empty:\n",
    "    print(\"There is no mismatch - It is safe to merge!!\", \"\\n\", 50 * \"#\")\n",
    "    full_table = pd.merge(\n",
    "        table_nomodelcol,\n",
    "        table_sizes,\n",
    "        left_on=(\"field\", \"id\"),\n",
    "        right_on=(\"field\", \"id\"),\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "####Now fix the center_x and center_y for using of astropy before exporting\n",
    "# full table:\n",
    "def fix_center_x(s):\n",
    "    # If there are 3 colons, replace the last colon with a dot\n",
    "    if s.count(\":\") == 3:\n",
    "        s = s[::-1].replace(\":\", \".\", 1)[::-1]\n",
    "    return s\n",
    "\n",
    "\n",
    "def fix_center_y(s):\n",
    "    # Replace the first two dots with colons\n",
    "    return s.replace(\".\", \":\", 2)\n",
    "\n",
    "\n",
    "# Apply to my DataFrame\n",
    "full_table[\"center_x\"] = full_table[\"center_x\"].astype(str).apply(fix_center_x)\n",
    "full_table[\"center_y\"] = full_table[\"center_y\"].astype(str).apply(fix_center_y)\n",
    "\n",
    "# df['Class'] = df['Class'].replace({'I': 'I/F', 'F': 'I/F'})\n",
    "# df['Group'] = df['Features'] + '+' + df['Class']\n",
    "# grouped = df.groupby('Group')\n",
    "\n",
    "full_table[\"Class\"] = full_table[\"Class\"].replace({\"I\": \"I_F\", \"F\": \"I_F\"})\n",
    "full_table[\"Group\"] = full_table[\"Stage\"].astype(str) + \"+\" + full_table[\"Class\"]\n",
    "full_table[\"Group\"] = full_table[\"Group\"].str.strip()\n",
    "# grouped = full_table.groupby('Group')\n",
    "\n",
    "# full_table_expanded = full_table.assign(Group=full_table['Features'].str.split(',')).explode('Group')\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'] + '+' + full_table_expanded['Class']#.replace({'I': 'I_F', 'F': 'I_F'})\n",
    "# full_table_expanded['Group'] = full_table_expanded['Group'].str.strip()\n",
    "\n",
    "try:\n",
    "    table_nomodelcol.to_csv(f\"{os.getcwd()}/table_paths.csv\", index=False)\n",
    "    print(\n",
    "        50 * \"#\",\n",
    "        \"\\n\",\n",
    "        \"Saved table_paths.csv successfully!\",\n",
    "        table_nomodelcol.info(verbose=True),\n",
    "        \"\\n\",\n",
    "        50 * \"#\",\n",
    "    )\n",
    "    table.to_csv(f\"{os.getcwd()}/fits_files.csv\", index=False)\n",
    "    print(\n",
    "        50 * \"#\",\n",
    "        \"\\n\",\n",
    "        \"Saved table.csv successfully!\",\n",
    "        table.info(verbose=True),\n",
    "        \"\\n\",\n",
    "        50 * \"#\",\n",
    "    )\n",
    "    full_table.to_csv(f\"{os.getcwd()}/full_table.csv\", index=False)\n",
    "    print(\n",
    "        50 * \"#\",\n",
    "        \"\\n\",\n",
    "        \"Saved full_table.csv successfully!\",\n",
    "        full_table.info(verbose=True),\n",
    "        \"\\n\",\n",
    "        50 * \"#\",\n",
    "    )\n",
    "\n",
    "    # full_table_expanded = full_table.explode('Group')\n",
    "    # full_table_expanded.to_csv(f\"{os.getcwd()}/full_table_expanded.csv\", index=False)\n",
    "    # print(50*\"#\", \"\\n\",\"Saved full_table_expanded.csv successfully!\",\n",
    "    #       full_table_expanded.info(verbose=True), \"\\n\", 50*\"#\")\n",
    "\n",
    "    # print(table.info(), full_table.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "# full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
